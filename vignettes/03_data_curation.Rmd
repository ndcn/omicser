---
title: "3-Data Curation"
author: "andy henrie"
date: "9/14/2021"
output:
  html_document: 
    keep_md: yes
    toc: true
  md_document:
    variant: gfm
---

```{r, setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The most crucial step when setting up your own app is _curating_ your data in preparation for loading into the browser.
There are two reasons for these steps:

- formatting the data into `AnnData` files, which creates a database accessible by the browser
- identifying the variables (e.g., columns in a table) that will be browsable, which specifies how data can be selected and/or manipulated in the browswer interface

As the _Curator_ you have the responsibility to understand the specific research questions involved in your data,
and how to allow these questions to be explored using a visualization tool.

The process of curating your data generally includes the following steps:

1. **Metadata documentation** - define the metadata and context for the dataset
2. **Raw data ingest** - translate the outputs of your quality-controlled (QC) data to database format; may include defining functions to read/process QC data
3. **Format as AnnData** - pack data into scanpy's AnnData structure
4. **Post-processing** - dimension reduction, compute relevant marginal quantities, define additional annotation and grouping variables, etc.
5. **Differential expression tables** - compute and/or format existing tables
6. **Write database** - create database and configuration files and store in a location the browser can locate

Each step of data curation is generally described below,
referencing the PBMC3k dataset from 10X Genomics as an example.
The complete script used for curation can be found in [`examples/browse_pbmc3k.R`](https://github.com/ndcn/omicser/blob/main/examples/browse_pbmc3k.R).
Additional examples of how the data curation process is applied to various data types and use cases can be found in the 
[`examples/` subdirectory](https://github.com/ndcn/omicser/tree/main/examples).

## Data organization

There are three main locations you'll need to specify while curating your data and otherwise preparing your browser app:

- **run directory**: location from which the browser is launched. For the PBMC3k example, we will refer to this as `OMICSER_RUN_DIR`, and create a new directory named `omicser_test/` which will contain the other content for this project. If you plan to make more extensive modifications to the browser, we recommend cloning the [`omicser`](https://github.com/ndcn/omicser) package and using the top level folder for your run directory.
- **location of data**: folder containing your -omics data, referred to as `RAW_DIR` and set to `raw_data/` in the PBMC3k example. This location is only used in the data curation steps.
- **location of database**: folder containing the formatted data produced by the data curation steps, packaged to be ingested for visualization in a browser. For the PBMC3k example, it is referred to as `DB_ROOT_PATH` and set as `test_db/` we will be working with a single dataset (and single dataset), though it is possible to visualize multiple datasets with the same browser configuration (i.e., this folder can potentially contain multiple databases).

### Example data from 10X Genomics

The example data used for this tutorial are from 
~3000 peripheral blood mononuclear cells (PBMCs) from a healthy donor.
Further information about the data is available at the [10X Genomics website](https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k).
These data have also been used in tutorials from [scanpy](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html)
and [Seurat](https://satijalab.org/seurat/archive/v3.0/pbmc3k_tutorial.html).

The [PBMC3k example script](https://github.com/ndcn/omicser/blob/main/examples/browse_pbmc3k.R)
includes code sections to help you install software/environments, download/organize data, and otherwise prepare for the data curation steps below.

## 1. Metadata setup

FIXME

## 2. Raw data ingest

FIXME

## 3. Format as AnnData

### `AnnData` Schema

The AnnData scheme requires us to define three pieces of data:

  1. *DATA* (\$X): a matrix  of measurements - e.g. transcriptomics - count matrix of cells by genes.
  2. *_FEATURE_ METADATA* (\$var): a table of `omic` annotation  -  e.g. gene/protein names, families, "highly variable genes", "is marker gene", etc.
  3. *_SAMPLE_ METADATA* (\$obs): a table of sample annotations - e.g.  cell types, sample #, batch ID sex, experiemntal condition, etc.

More info here https://cran.r-project.org/web/packages/anndata/readme/README.html 

![Anndata scheme](../inst/anndata_for_r.png)
              
### Loading the data

In addition to these three pieces differential expression tables need to be pre-computed.

Here are some of the key helper functions and he section they fall into.

Here is an example of loading three data files and then pakaging them with a "helper function" (defined in section #2 of the example curation script) into the `data_list` which will be used by the next stage.

#### `setup_database()`

The `omicser::setup_database()` function packages the separate tables -- DATA matrix, omic FEATURE METADATA annotations, and SAMPLE METADATA -- into the anndata object.  This function can also take the name of a seurat object file.  


``` {r , RM-prep-3, eval=FALSE}
adata <- omicser::setup_database(database_name=DB_NAME,
                              data_in=data_list,
                              db_meta=NULL ,
                              re_pack=TRUE)
```


Once we have packed the data into the `anndata` object we can leverage `scanpy` and the `reticulate` python backend to do dimension reduction and clustering. 
Although this stage is not necessary, it demonstrates the bridge to `cellxgene`.

``` {r, RM-prep-4, eval=FALSE}
#==== 4a. dimension reduction - PCA / umap ========================================================
sc <- import("scanpy")
# scanpy pre-processing - sc$pp
sc$pp$pca(adata)
sc$pp$neighbors(adata)
sc$tl$leiden(adata)
sc$tl$umap(adata)
```

## 5. Create differential expression tables

This is probably the trickiest part of the curation  Fortunately we have some helper functions to help us compute them.  Often -- especially for _prote-_ omic databases -- differential expressions are computed as the output of the instrumentataion by a commercial software.  These algorithms leverage bespoke statistics, so it will be best to reformat those tables. 

### DE Table Schema

Most proteomic, metabelomic and lipidomic data will have differential calculations at the output of the instrumentation (which leverages know statastical assumptions of the quantifications) we can also use scanpys tools to compute differential expression.  The diff_exp tables will be needed for volcano plots either way.

The differential expression table has these fields:

   - `group` - the comparison   {names}V{reference}
   - `names` - what are we comparing?
   - `obs_name`  - name of the meta data variable
   - `test_type` - what statistic are we using
   - `reference` - the denomenator. or the condition we are comparing expressions values to
   - `comp_type` - grpVref or grpVrest. rest is all other conditions
   - `logfoldchanges` - log2(name/reference)
   - `scores` - statistic score
   - `pvals` - pvalues from the stats test. e.g. t-test
   - `pvals_adj` - adjusted pvalue (Q)
   - `versus` - label which we will choose in the browser
   
 
### omicser::compute_de_table()

In [`R/pre_process_helpers.R`](../R/pre_process_helpers.R) theres a function which leverages `scanpy` and the `anndata` format we have packed to do differential expression.  We just need to pass a few quantites and it returns a properly formatted differential expression table.

omicser::compute_de_table()

parameters:

  - `adata` - the anndata object
  - `comp_types` - what kind of comparisons? there are two types
    - "allVrest" which takes each of our experimental conditions in turn and compares against the "rest" of the data.
    - "{a}V{b}" or "firstgroupVsecondgroup" which compares the experimental condition "firstgroup" against "secondgroup"
  - `test_types` - statistical tests.  See the examples or `scanpy` documentation for which test types are available.
  - `obs_names` -name of the adata$obs column defining the comparision groups
  - `sc` - the scanpy data object we imported with `reticulate`

Here's an example which computes a differential expression with a `wilcoxon` test of significance for each _disease_ with respect to the rest of the distease states, AND for each _cell_type_ with-respect-to the "rest of" the _cell_type_ s. 

``` {r RM-prep-5, eval=FALSE}
sc <- reticulate::import("scanpy")
test_types <- c('wilcoxon')
comp_types <- c('allVrest')
obs_names <- c('disease','cell_type')
diff_exp <- omicser::compute_de_table(adata,comp_types, test_types, obs_names,sc)

```

## 6. Write the _DATABASE_

Finally we write this the anndata data object to our _database_DATABASE_ folder.   In the examples contained in the `vignettes/` folder we defined `DS_ROOT_PATH <- "test_db"`, and `DB_NAME <- "domenico_stem_cell"` .

``` {r, RM-prep-6, eval=FALSE}
adata$write_h5ad(filename=file.path(DS_ROOT_PATH,DB_NAME,"db_data.h5ad"))
```

In the end each DATABASE folder should now these three files:
1. `db_data.h5ad` - the anndata object          
2. `db_de_table.rds` - differntial expression table
3, `db_meta.yml` - list of database 'meta' information

You might also want to save some _intermediate_ files such as in the [examples](examples/curate_pbmc3k.R) which also generate: `normalized_data.h5ad`,`core_data.h5ad`,and `norm_data_plus_dr.h5ad`.

We are almost there.  In the next section we will cover the configuration which will add a `db_config.yml` files to the _DATABASE_ directory, and create an [`omicser_options.yml`](omicser_options.yml) in the directory where the app will be executed.

In the next step,
we'll [configure the browser](04_configuration.md).
